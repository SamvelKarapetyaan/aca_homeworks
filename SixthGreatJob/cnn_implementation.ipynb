{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_diabetes\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer:\n",
    "    \"\"\"\n",
    "    Represents a neural network layer.\n",
    "    ==========\n",
    "    Attributes:\n",
    "    ----------\n",
    "        size (int): Number of neurons in the layer.\n",
    "        input_layer (bool): Whether the layer is an input layer.\n",
    "        activation (str): Activation function for the layer.\n",
    "        use_bias (bool): Whether to use bias in the layer.\n",
    "        optimizer (str): Optimization algorithm used for the layer.\n",
    "        w (numpy.ndarray): Weights matrix for the layer.\n",
    "\n",
    "    Methods:\n",
    "    ---------\n",
    "        activationFunction(z):\n",
    "            Apply the activation function to the given input.\n",
    "\n",
    "        __call__(X):\n",
    "            Perform a forward pass through the layer.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            size, \n",
    "            *, \n",
    "            input_layer: bool = False,\n",
    "            activation: str = \"linear\",\n",
    "            use_bias: bool = True,\n",
    "            ):\n",
    "        \"\"\"\n",
    "        Initialize a neural network layer.\n",
    "\n",
    "        Args:\n",
    "            size (int): Count of neurons in the layer.\n",
    "            input_layer (bool, optional): Whether the layer is an input layer. Defaults to False.\n",
    "            activation (str, optional): Activation function for the layer. Can be \"linear\", \"relu\", or \"sigmoid\". Defaults to \"linear\".\n",
    "            use_bias (bool, optional): Whether to use bias in the layer. Defaults to True.\n",
    "        \"\"\"\n",
    "            \n",
    "        \n",
    "        self.size = size\n",
    "        self.input_layer = input_layer\n",
    "        self.activation = activation\n",
    "        self.use_bias = use_bias\n",
    "\n",
    "        self.optimizer = None # Optimizer for layer\n",
    "\n",
    "        self._input = None\n",
    "        self._output = None\n",
    "\n",
    "        self.w = None # Weights matrix\n",
    "        self._weight_gradient = None # Weights derivative matrix\n",
    "        self._bias_gradient = None # Biases derivative vector\n",
    "\n",
    "    def _weightInit(self, input_size):\n",
    "        \"\"\"\n",
    "        Initialize the weights matrix based on the input size.\n",
    "\n",
    "        Args:\n",
    "            input_size (int): Size of the input.\n",
    "\n",
    "        Notes:\n",
    "            Only executed for layers other than the input layer.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.input_layer:\n",
    "            return # input_layer doesn't need weights\n",
    "\n",
    "        self.w = np.random.normal(loc = 0, scale = 1 / input_size, size=(input_size, self.size))\n",
    "        # Initialize weights matrix using a normal distribution with mean 0 and variance 1 / input_size\n",
    "\n",
    "        self.bias = np.zeros((1, self.size))\n",
    "        # Initialize biases as zeros\n",
    "\n",
    "    def activationFunction(self, z):\n",
    "        \"\"\"\n",
    "        Apply the activation function to the given input.\n",
    "\n",
    "        Args:\n",
    "            z (numpy.ndarray): Input to the activation function.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Output after applying the activation function.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.activation == \"linear\":\n",
    "            return z\n",
    "\n",
    "        if self.activation == \"relu\":\n",
    "            return np.maximum(z, np.zeros(z.shape))\n",
    "\n",
    "        if self.activation == \"sigmoid\":\n",
    "            return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def _setOptimizer(self, optimizer, beta_1, beta_2):\n",
    "        \"\"\"\n",
    "        Set the optimizer and initialize optimizer-specific variables.\n",
    "\n",
    "        Args:\n",
    "            optimizer (str): Optimization algorithm to use.\n",
    "            beta_1 (float): Value for the optimizer parameter beta_1.\n",
    "            beta_2 (float): Value for the optimizer parameter beta_2.\n",
    "\n",
    "        Notes:\n",
    "            - Only executed for layers other than the input layer.\n",
    "            - Sets the optimizer and initializes optimizer-specific variables based on the chosen optimizer.\n",
    "            - For each optimizer, the corresponding variables are initialized.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.input_layer:\n",
    "            return\n",
    "\n",
    "        self.optimizer = optimizer\n",
    "        self._b1 = beta_1\n",
    "        self._b2 = beta_2\n",
    "\n",
    "        if self.optimizer == \"adagrad\":\n",
    "            self._weight_v = np.zeros(self.w.shape)\n",
    "            # Initialize weight-specific variables for AdaGrad\n",
    "\n",
    "            if self.use_bias:\n",
    "                self._bias_v = np.zeros(self.bias.shape)\n",
    "                # Initialize bias-specific variables for AdaGrad\n",
    "\n",
    "        if self.optimizer == 'adam':\n",
    "            self._iter = 0  # Calculate iterations\n",
    "\n",
    "            self._weight_m = np.zeros(self.w.shape)\n",
    "            self._weight_v = np.zeros(self.w.shape)\n",
    "            # Initialize weight-specific variables for Adam\n",
    "\n",
    "            if self.use_bias:\n",
    "                self._bias_m = np.zeros(self.bias.shape)\n",
    "                self._bias_v = np.zeros(self.bias.shape)\n",
    "                # Initialize bias-specific variables for Adam\n",
    "\n",
    "        if self.optimizer == 'rms_prop':\n",
    "            self._weight_v = np.zeros(self.w.shape)\n",
    "\n",
    "            if self.use_bias:\n",
    "                self._bias_v = np.zeros(self.bias.shape)\n",
    "            # Initialize weight and bias-specific variables for RMSprop\n",
    "\n",
    "        if self.optimizer == 'gdm':\n",
    "            self._weight_m = np.zeros(self.w.shape)\n",
    "\n",
    "            if self.use_bias:\n",
    "                self._bias_m = np.zeros(self.bias.shape)\n",
    "            # Initialize weight and bias-specific variables for Gradient Descent with Momentum   \n",
    "\n",
    "    def _activationDerivative(self):\n",
    "        \"\"\"\n",
    "        Compute the derivative of the activation function.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Derivative of the activation function.\n",
    "\n",
    "        Notes:\n",
    "            Only supports the \"linear\", \"relu\", and \"sigmoid\" activation functions.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.activation == \"linear\":\n",
    "            return 1\n",
    "\n",
    "        if self.activation == \"relu\":\n",
    "            return (self._output > 0) * 1\n",
    "\n",
    "        if self.activation == \"sigmoid\":\n",
    "            return self._output * (1 - self._output)\n",
    "\n",
    "    def _setGrad(self, grad):\n",
    "        \"\"\"\n",
    "        Calculate the gradients of weights and bias for backpropagation.\n",
    "\n",
    "        Args:\n",
    "            grad (numpy.ndarray): Gradient from the previous layer.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Gradient to be passed to the previous layer.\n",
    "\n",
    "        Notes:\n",
    "            Only executed for layers other than the input layer.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.input_layer:\n",
    "            return\n",
    "        \n",
    "        grad = grad * self._activationDerivative()\n",
    "        self._weight_gradient = self._input.T @ grad\n",
    "\n",
    "        if self.use_bias:\n",
    "            self._bias_gradient = grad.sum(axis=0, keepdims=True)\n",
    "\n",
    "        return grad @ self.w.T\n",
    "    \n",
    "    def _updateGrad(self, learning_rate):\n",
    "        \"\"\"\n",
    "        Update the weights and bias based on the computed gradients.\n",
    "\n",
    "        Args:\n",
    "            learning_rate (float): Learning rate for gradient descent.\n",
    "\n",
    "        Notes:\n",
    "            - Only executed for layers other than the input layer.\n",
    "            - Updates the weights and biases based on the computed gradients and the chosen optimizer.\n",
    "            - For each optimizer, the corresponding update rule is applied.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "        if self.input_layer:\n",
    "            return\n",
    "\n",
    "        eps = 10e-8 # Optimizer's epsilon\n",
    "\n",
    "        if self.optimizer == \"gd\":\n",
    "            self.w -= learning_rate * self._weight_gradient\n",
    "            if self.use_bias:\n",
    "                self.bias -= learning_rate * self._bias_gradient\n",
    "\n",
    "        if self.optimizer == \"adagrad\":\n",
    "            self._weight_v += np.square(self._weight_gradient)\n",
    "            learning_rate_weight = learning_rate / ( np.sqrt(self._weight_v) + eps)\n",
    "\n",
    "            self.w -= learning_rate_weight * self._weight_gradient\n",
    "\n",
    "            if self.use_bias:\n",
    "                self._bias_v += np.square(self._bias_gradient)\n",
    "                learning_rate_bias = learning_rate / ( np.sqrt(self._bias_v) + eps)\n",
    "\n",
    "                self.bias -= learning_rate_bias * self._bias_gradient\n",
    "\n",
    "        if self.optimizer == 'adam':\n",
    "            self._iter += 1\n",
    "\n",
    "            self._weight_m = self._b1 * self._weight_m + (1- self._b1) * self._weight_gradient\n",
    "            self._weight_v = self._b2 * self._weight_v + (1- self._b2) * np.square(self._weight_gradient)\n",
    "\n",
    "            weight_m = self._weight_m / (1 - np.power(self._b1, self._iter))\n",
    "            weight_v = self._weight_v / (1 - np.power(self._b2, self._iter))\n",
    "\n",
    "            self.w -= learning_rate * weight_m / (np.sqrt(weight_v) + eps) # Updating\n",
    "\n",
    "            if self.use_bias:\n",
    "                self._bias_m = self._b1 * self._bias_m + (1- self._b1) * self._bias_gradient\n",
    "                self._bias_v = self._b2 * self._bias_v + (1- self._b2) * np.square(self._bias_gradient)\n",
    "\n",
    "                bias_m = self._bias_m / (1 - np.power(self._b1, self._iter)) \n",
    "                bias_v = self._bias_v / (1 - np.power(self._b2, self._iter))\n",
    "\n",
    "\n",
    "                self.bias -= learning_rate * bias_m / (np.sqrt(bias_v) + eps) # Updating\n",
    "\n",
    "        \n",
    "        if self.optimizer == 'rms_prop':\n",
    "            self._weight_v = self._b2 * self._weight_v + (1- self._b2) * np.square(self._weight_gradient)\n",
    "\n",
    "            learning_rate_weight = learning_rate / ( np.sqrt(self._weight_v) + eps)\n",
    "\n",
    "            self.w -= learning_rate_weight * self._weight_gradient\n",
    "\n",
    "            if self.use_bias:\n",
    "                self._bias_v = self._b2 * self._bias_v + (1- self._b2) * np.square(self._bias_gradient)\n",
    "                learning_rate_bias = learning_rate / ( np.sqrt(self._bias_v) + eps)\n",
    "\n",
    "                self.bias -= learning_rate_bias * self._bias_gradient\n",
    "\n",
    "        if self.optimizer == 'gdm':\n",
    "            self._weight_m = self._b2 * self._weight_m + (1 - self._b2) * self._weight_gradient\n",
    "\n",
    "            self.w -= learning_rate * self._weight_m\n",
    "\n",
    "            if self.use_bias:\n",
    "                self._bias_m = self._b2 * self._bias_m + (1 - self._b2) * self._bias_gradient\n",
    "\n",
    "                self.bias -= learning_rate * self._bias_m\n",
    "\n",
    "    def __call__(self, X):\n",
    "        \"\"\"\n",
    "        Perform a forward pass through the layer.\n",
    "\n",
    "        Args:\n",
    "            X (numpy.ndarray): Input to the layer.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Output of the layer after applying the activation function.\n",
    "        \"\"\"\n",
    "        if self.input_layer:\n",
    "            return X\n",
    "        \n",
    "        self._input = X\n",
    "        self._output = self.activationFunction(X @ self.w + self.bias)\n",
    "\n",
    "        return self._output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d:\n",
    "    def __init__(\n",
    "            self,\n",
    "            size: int,\n",
    "            kernel_size: tuple,\n",
    "            *,\n",
    "            padding: int = 0,\n",
    "            stride: int = 1,\n",
    "            activation: str = \"linear\",\n",
    "            mode: str = \"rgb\",\n",
    "            pooling: str = None,\n",
    "            use_bias: bool = True,\n",
    "        ):\n",
    "        self.size = size\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        self.padding = padding\n",
    "        self.stride = stride\n",
    "        self.activation = activation\n",
    "        self.mode = mode\n",
    "        self.pooling = pooling\n",
    "        self.use_bias = use_bias\n",
    "\n",
    "        self.kernel = None\n",
    "        self.optimizer = None\n",
    "\n",
    "        self._kernel_gradient = None # Kernel derivative matrix\n",
    "\n",
    "        if self.use_bias:\n",
    "            self._bias_gradient = None # Biases derivative vector\n",
    "\n",
    "    def _weightInit(self, depth):\n",
    "\n",
    "        self.kernel_size = self.kernel_size + (depth, ) # (kenel_size, depth)\n",
    "\n",
    "        # Initialize weights matrix using a normal distribution with mean 0 and variance 1 / input_size\n",
    "        self.kernel = np.random.normal(loc = 0, scale = 1 / (self.kernel_size[0] * self.kernel_size[1] * self.kernel_size[2]), size=(self.kernel_size + (self.size,)))        \n",
    "\n",
    "        # Description here:\n",
    "        self._kernel_gradient = np.zeros_like(self.kernel)\n",
    "\n",
    "\n",
    "        if self.use_bias:\n",
    "            # Initialize biases as zeros\n",
    "            self.bias = np.zeros(self.size)\n",
    "\n",
    "            # Description here:\n",
    "            self._bias_gradient = np.zeros_like(self.bias)\n",
    "\n",
    "    \n",
    "    def activationFunction(self, z):\n",
    "        \"\"\"\n",
    "        Apply the activation function to the given input.\n",
    "\n",
    "        Args:\n",
    "            z (numpy.ndarray): Input to the activation function.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Output after applying the activation function.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.activation == \"linear\":\n",
    "            return z\n",
    "\n",
    "        if self.activation == \"relu\":\n",
    "            return np.maximum(z, np.zeros(z.shape))\n",
    "\n",
    "    def _setOptimizer(self, optimizer, beta_1, beta_2):\n",
    "        self.optimizer = optimizer\n",
    "        self._b1 = beta_1\n",
    "        self._b2 = beta_2\n",
    "\n",
    "\n",
    "        if self.optimizer == \"adagrad\":\n",
    "            self._weight_v = np.zeros(self.kernel.shape)\n",
    "            # Initialize weight-specific variables for AdaGrad\n",
    "\n",
    "            if self.use_bias:\n",
    "                self._bias_v = np.zeros(self.bias.shape)\n",
    "                # Initialize bias-specific variables for AdaGrad\n",
    "\n",
    "        if self.optimizer == 'adam':\n",
    "            self._iter = 0  # Calculate iterations\n",
    "\n",
    "            self._weight_m = np.zeros(self.kernel.shape)\n",
    "            self._weight_v = np.zeros(self.kernel.shape)\n",
    "            # Initialize weight-specific variables for Adam\n",
    "\n",
    "            if self.use_bias:\n",
    "                self._bias_m = np.zeros(self.bias.shape)\n",
    "                self._bias_v = np.zeros(self.bias.shape)\n",
    "                # Initialize bias-specific variables for Adam\n",
    "\n",
    "        if self.optimizer == 'rms_prop':\n",
    "            self._weight_v = np.zeros(self.kernel.shape)\n",
    "\n",
    "            if self.use_bias:\n",
    "                self._bias_v = np.zeros(self.bias.shape)\n",
    "            # Initialize weight and bias-specific variables for RMSprop\n",
    "\n",
    "        if self.optimizer == 'gdm':\n",
    "            self._weight_m = np.zeros(self.kernel.shape)\n",
    "\n",
    "            if self.use_bias:\n",
    "                self._bias_m = np.zeros(self.bias.shape)\n",
    "            # Initialize weight and bias-specific variables for Gradient Descent with Momentum   \n",
    "\n",
    "\n",
    "    def _setGrad(self, grad):\n",
    "        if self.pooling:\n",
    "            grad = grad[np.newaxis, ...]\n",
    "\n",
    "        self._kernel_gradient = grad.reshape(-1, grad.shape[-1]).sum(axis=0).reshape(1, 1, 1, -1) * self._kernel_gradient\n",
    "\n",
    "        if self.use_bias:\n",
    "            self._bias_gradient = grad.reshape(-1, grad.shape[-1]).sum(axis=0)\n",
    "\n",
    "        for i in range(grad.shape[0]):\n",
    "            axis1_x1, axis1_x2 = self._indices_axis1[i]\n",
    "            for j in range(grad.shape[1]):\n",
    "                axis2_y1, axis2_y2 = self._indices_axis2[j]\n",
    "\n",
    "                self._input_gradient[axis1_x1:axis1_x2, axis2_y1:axis2_y2] *= grad[i, j].sum()\n",
    "\n",
    "\n",
    "        return self._input_gradient\n",
    "\n",
    "    def _updateGrad(self, learning_rate):\n",
    "        eps = 10e-8 # Optimizer's epsilon\n",
    "\n",
    "        if self.optimizer == \"gd\":\n",
    "            self.kernel -= learning_rate * self._kernel_gradient\n",
    "\n",
    "            if self.use_bias:\n",
    "                self.bias -= learning_rate * self._bias_gradient\n",
    "\n",
    "        if self.optimizer == \"adagrad\":\n",
    "            self._weight_v += np.square(self._kernel_gradient)\n",
    "            learning_rate_weight = learning_rate / ( np.sqrt(self._weight_v) + eps)\n",
    "\n",
    "            self.kernel -= learning_rate_weight * self._kernel_gradient\n",
    "\n",
    "            if self.use_bias:\n",
    "                self._bias_v += np.square(self._bias_gradient)\n",
    "                learning_rate_bias = learning_rate / ( np.sqrt(self._bias_v) + eps)\n",
    "\n",
    "                self.bias -= learning_rate_bias * self._bias_gradient\n",
    "\n",
    "        if self.optimizer == 'adam':\n",
    "            self._iter += 1\n",
    "\n",
    "            self._weight_m = self._b1 * self._weight_m + (1- self._b1) * self._kernel_gradient\n",
    "            self._weight_v = self._b2 * self._weight_v + (1- self._b2) * np.square(self._kernel_gradient)\n",
    "\n",
    "            weight_m = self._weight_m / (1 - np.power(self._b1, self._iter))\n",
    "            weight_v = self._weight_v / (1 - np.power(self._b2, self._iter))\n",
    "\n",
    "            self.kernel -= learning_rate * weight_m / (np.sqrt(weight_v) + eps) # Updating\n",
    "\n",
    "            if self.use_bias:\n",
    "                self._bias_m = self._b1 * self._bias_m + (1- self._b1) * self._bias_gradient\n",
    "                self._bias_v = self._b2 * self._bias_v + (1- self._b2) * np.square(self._bias_gradient)\n",
    "\n",
    "                bias_m = self._bias_m / (1 - np.power(self._b1, self._iter)) \n",
    "                bias_v = self._bias_v / (1 - np.power(self._b2, self._iter))\n",
    "\n",
    "\n",
    "                self.bias -= learning_rate * bias_m / (np.sqrt(bias_v) + eps) # Updating\n",
    "\n",
    "        \n",
    "        if self.optimizer == 'rms_prop':\n",
    "            self._weight_v = self._b2 * self._weight_v + (1- self._b2) * np.square(self._kernel_gradient)\n",
    "\n",
    "            learning_rate_weight = learning_rate / ( np.sqrt(self._weight_v) + eps)\n",
    "\n",
    "            self.kernel -= learning_rate_weight * self._kernel_gradient\n",
    "\n",
    "            if self.use_bias:\n",
    "                self._bias_v = self._b2 * self._bias_v + (1- self._b2) * np.square(self._bias_gradient)\n",
    "                learning_rate_bias = learning_rate / ( np.sqrt(self._bias_v) + eps)\n",
    "\n",
    "                self.bias -= learning_rate_bias * self._bias_gradient\n",
    "\n",
    "        if self.optimizer == 'gdm':\n",
    "            self._weight_m = self._b2 * self._weight_m + (1 - self._b2) * self._kernel_gradient\n",
    "\n",
    "            self.kernel -= learning_rate * self._weight_m\n",
    "\n",
    "            if self.use_bias:\n",
    "                self._bias_m = self._b2 * self._bias_m + (1 - self._b2) * self._bias_gradient\n",
    "\n",
    "                self.bias -= learning_rate * self._bias_m\n",
    "                \n",
    "    def __call__(self, tensor):\n",
    "        tensor = tensor[..., np.newaxis]\n",
    "\n",
    "        self._input = tensor\n",
    "\n",
    "        tensor_shape = np.array(tensor.shape[:2])\n",
    "\n",
    "        output_shape = ((tensor_shape + 2 * self.padding - self.kernel_size[:2]) / self.stride).astype(int) + 1\n",
    "        output_shape = np.concatenate([output_shape, [self.size]])\n",
    "\n",
    "        self._output = np.zeros(output_shape)\n",
    "\n",
    "        self._indices_axis1 = [(i - self.kernel_size[0], i) for i in range(self.kernel_size[0], tensor_shape[0] + 1, self.stride)]\n",
    "        self._indices_axis2 = [(i - self.kernel_size[0], i) for i in range(self.kernel_size[1], tensor_shape[1] + 1, self.stride)]\n",
    "\n",
    "        self._input_gradient = np.copy(tensor)\n",
    "\n",
    "        for i in range(output_shape[0]):\n",
    "            axis1_x1, axis1_x2 = self._indices_axis1[i]\n",
    "            for j in range(output_shape[1]):\n",
    "\n",
    "                axis2_y1, axis2_y2 = self._indices_axis2[j]\n",
    "\n",
    "                self._output[i, j] = (tensor[axis1_x1:axis1_x2, axis2_y1:axis2_y2] * self.kernel).sum(axis=(0, 1, 2))\n",
    "                self._kernel_gradient += tensor[axis1_x1:axis1_x2, axis2_y1:axis2_y2] * (self._output[i, j] > 0) # ReLU implementation\n",
    "                self._input_gradient[axis1_x1:axis1_x2, axis2_y1:axis2_y2] += self.kernel.sum(axis=3, keepdims=True)\n",
    "\n",
    "\n",
    "        self._output = self.activationFunction(self._output) # + self.bias\n",
    "\n",
    "        # May be added Max pooling\n",
    "        # if self.pooling == \"max\":\n",
    "        #     return output.max(axis=(0, 1))[np.newaxis, ...] # (1, output_shape)\n",
    "        \n",
    "        if self.pooling == \"average\":\n",
    "            self._kernel_gradient /= self._output.shape[0] * self._output.shape[1]\n",
    "            self._input_gradient /= self._output.shape[0] * self._output.shape[1]\n",
    "\n",
    "            return self._output.mean(axis=(0, 1))[np.newaxis, ...] # (1, output_shape)\n",
    "        \n",
    "\n",
    "        return self._output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeauralNetwork:\n",
    "    \"\"\"\n",
    "    Neural Network\n",
    "    ==============\n",
    "\n",
    "    A neural network model for deep learning.\n",
    "\n",
    "    The `NeuralNetwork` class allows you to create and train a neural network model with customizable architecture and\n",
    "    training parameters.\n",
    "\n",
    "    Args:\n",
    "    -------\n",
    "        layers (list): List of Layer objects defining the network architecture.\n",
    "        loss_function (str, optional): Loss function to use. Defaults to \"mse\".\n",
    "        learning_rate (float, optional): Learning rate for gradient descent. Defaults to 0.01.\n",
    "        verbose (bool, optional): Whether to display training progress. Defaults to False.\n",
    "        optimizer (str, optional): Optimization algorithm to use for updating weights during training. Defaults to \"gd\".\n",
    "        epochs (int, optional): Number of epochs for training. Defaults to 1.\n",
    "        batch_size (int, optional): Batch size for training. Defaults to 32.\n",
    "        beta_1 (float, optional): Parameter for the optimizer. Defaults to 0.9.\n",
    "        beta_2 (float, optional): Parameter for the optimizer. Defaults to 0.999.\n",
    "\n",
    "    Methods:\n",
    "    --------\n",
    "        __init__(self, layers, loss_function=\"mse\", learning_rate=0.01, verbose=False, optimizer=\"gd\", epochs=1,\n",
    "                 batch_size=32, beta_1=0.9, beta_2=0.999)\n",
    "            Initializes a neural network object.\n",
    "        lossFunction(self, y_true, y_pred)\n",
    "            Compute the loss between the true values and predicted values.\n",
    "        fit(self, X, y)\n",
    "            Train the neural network on the given input-output pairs.\n",
    "        predict(self, X)\n",
    "            Perform predictions using the trained neural network.\n",
    "        forward(self, X)\n",
    "            Perform a forward pass through the network.\n",
    "        backward(self, y_pred, y_true)\n",
    "            Perform backpropagation to update the weights of the network.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            layers: list, \n",
    "            loss_function: str = \"mse\", \n",
    "            softmax: bool = False,\n",
    "            learning_rate = 0.01,\n",
    "            verbose: bool = False,\n",
    "            optimizer: str = \"gd\",\n",
    "            epochs: int = 1, \n",
    "            batch_size: int = 32,\n",
    "            beta_1: float = 0.9,\n",
    "            beta_2: float = 0.999\n",
    "            ):\n",
    "        \"\"\"\n",
    "        Initialize a neural network.\n",
    "        --------\n",
    "        Args:\n",
    "        --------\n",
    "            layers (list): List of Layer objects defining the network architecture. \n",
    "            loss_function (str, optional): Loss function to use. Defaults to \"mse\".\n",
    "            optimizer (str, optional): Optimization algorithm to use for updating weights during training.\n",
    "                Options include:\n",
    "                - \"gd\" (Gradient Descent): Standard gradient descent.\n",
    "                - \"sgd\" (Stochastic Gradient Descent): Update weights using a single sample at a time.\n",
    "                - \"adagrad\" (Adaptive Gradient): Adjust the learning rate based on the frequency of feature occurrences.\n",
    "                - \"adam\" (Adam): Adaptive Moment Estimation algorithm.\n",
    "                - \"rms_prop\" (Root Mean Square Propagation): Adapt the learning rate based on the moving average of squared gradients.\n",
    "                - \"gdm\" (Gradient Descent with Momentum): Add momentum to the gradient descent algorithm.\n",
    "                Defaults to \"gd\".\n",
    "\n",
    "            learning_rate (float, optional): Learning rate for gradient descent. Defaults to 0.01.\n",
    "            epochs (int, optional): Number of epochs for training. Defaults to 1.\n",
    "            batch_size (int, optional): Batch size for training. Defaults to 32.\n",
    "            verbose (bool, optional): Whether to display training progress. Defaults to False.\n",
    "\n",
    "            beta_1 (float, optional): Parameter for the optimizer. Defaults to 0.9.\n",
    "            beta_2 (float, optional): Parameter for the optimizer. Defaults to 0.999.\n",
    "        \"\"\"\n",
    "\n",
    "        self.layers = layers\n",
    "        self.loss_function = loss_function\n",
    "        self.softmax = softmax\n",
    "        self.learning_rate = learning_rate\n",
    "        self.verbose = verbose\n",
    "        self.optimizer = optimizer  # Optimizer for all layers\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.beta_1 = beta_1  # Optimizer parameters\n",
    "        self.beta_2 = beta_2  # Optimizer parameters\n",
    "\n",
    "\n",
    "        # Weights initializing:\n",
    "        self.layers[0]._weightInit(3) # TODO: KEEP ATTENTION MAY BE CHANGED\n",
    "        self.layers[0]._setOptimizer(self.optimizer, self.beta_1, self.beta_2)\n",
    "\n",
    "        for i in range(1, len(self.layers)):\n",
    "            self.layers[i]._weightInit(self.layers[i - 1].size)\n",
    "            self.layers[i]._setOptimizer(self.optimizer, self.beta_1, self.beta_2)\n",
    "            # Initialize weights for each layer and set the optimizer\n",
    "\n",
    "    def lossFunction(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Compute the loss between the true values and predicted values.\n",
    "        \n",
    "        Args:\n",
    "            y_true (numpy.ndarray): True values.\n",
    "            y_pred (numpy.ndarray): Predicted values.\n",
    "\n",
    "        Returns:\n",
    "            float: Loss value.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.loss_function == \"mse\":\n",
    "            return 0.5 * np.mean(np.linalg.norm(y_pred - y_true, axis=1)**2)\n",
    "        \n",
    "        if self.loss_function == \"cross_entropy\":\n",
    "            return -np.log(y_pred[0, np.argmax(y_true)])\n",
    "\n",
    "        # Can be added\n",
    "\n",
    "    def _lossFunctionDerivative(self, y_pred, y_true):\n",
    "        \"\"\"\n",
    "        Compute the derivative of the loss function.\n",
    "\n",
    "        Args:\n",
    "            y_pred (numpy.ndarray): Predicted values.\n",
    "            y_true (numpy.ndarray): True values.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Derivative of the loss function.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.loss_function == \"mse\":\n",
    "            derivative = 1 / len(y_pred) * (y_pred - y_true)\n",
    "        \n",
    "        if self.loss_function == \"cross_entropy\":\n",
    "            derivative = np.zeros_like(y_pred.flatten())\n",
    "            derivative[np.argmax(y_true)] = - 1 / y_pred[0, np.argmax(y_true)]\n",
    "\n",
    "        # Can be added\n",
    "\n",
    "        if self.softmax:\n",
    "            softmax_der = np.zeros_like(y_pred)\n",
    "            softmax_der[0, np.argmax(y_true)] = 1\n",
    "            softmax_der = -y_pred[0, np.argmax(y_true)] * (y_pred - softmax_der)\n",
    "            derivative = derivative * softmax_der\n",
    "\n",
    "        return derivative\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the neural network on the given input-output pairs.\n",
    "\n",
    "        Args:\n",
    "            X (numpy.ndarray): Input data.\n",
    "            y (numpy.ndarray): Output data.\n",
    "\n",
    "        Notes:\n",
    "            - Reshape y to a column vector (shape: (n_samples, output_size)).\n",
    "        \"\"\"\n",
    "        for _ in range(self.epochs):\n",
    "            for i in range(len(y)):\n",
    "                pred = self.forward(X[i])\n",
    "\n",
    "                if self.verbose:\n",
    "                    # process_percent = int(iter / epoch_len * 10)\n",
    "                    print(f\"\\r Epoch {_ + 1}/{self.epochs}: loss: {self.lossFunction(y[i], pred)}\",end='')\n",
    "                    \n",
    "                self.backward(pred, y[i])\n",
    "            \n",
    "        if self.verbose:\n",
    "            print(f\"\\r Epoch {self.epochs}: loss: {self.lossFunction(y[i], pred)}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Perform predictions using the trained neural network.\n",
    "\n",
    "        Args:\n",
    "            X (numpy.ndarray): Input data.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Predicted output data.\n",
    "        \"\"\"\n",
    "\n",
    "        return self.forward(X)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Perform a forward pass through the network.\n",
    "\n",
    "        Args:\n",
    "            X (numpy.ndarray): Input data.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray\n",
    "        \"\"\"\n",
    "\n",
    "        X_ = np.copy(X)\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            X_ = layer(X_)\n",
    "\n",
    "        if self.softmax:\n",
    "            self.probs = np.exp(X_)\n",
    "            self.probs = self.probs / np.sum(self.probs)\n",
    "            return self.probs\n",
    "\n",
    "        return X_\n",
    "\n",
    "    def backward(self, y_pred, y_true):\n",
    "        \"\"\"\n",
    "        Perform backpropagation to update the weights of the network.\n",
    "\n",
    "        Args:\n",
    "            y_pred (numpy.ndarray): Predicted values.\n",
    "            y_true (numpy.ndarray): True values.\n",
    "        \"\"\"\n",
    "        \n",
    "        gradient = self._lossFunctionDerivative(y_pred, y_true)\n",
    "\n",
    "\n",
    "        loss = self.lossFunction(y_true, y_pred)\n",
    "        if loss < 1e-20:\n",
    "            return\n",
    "\n",
    "        for layer in reversed(self.layers):\n",
    "            gradient = layer._setGrad(gradient)\n",
    "            layer._updateGrad(self.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeData(path, labels):\n",
    "    X_train, y_train = [], []\n",
    "    for image_path in os.listdir(path):\n",
    "        image = Image.open(path + image_path)\n",
    "        image_array = np.asarray(image) / 256\n",
    "\n",
    "        label = np.zeros(3)\n",
    "        label[[labels[image_path.split(\"_\")[0]]]] = 1\n",
    "\n",
    "        X_train.append(image_array)\n",
    "        y_train.append(label)  \n",
    "\n",
    "    return X_train, y_train   \n",
    "\n",
    "labels = {\n",
    "    \"cucumber\": 0,\n",
    "    \"eggplant\": 1,\n",
    "    \"mushroom\": 2,\n",
    "}\n",
    "\n",
    "path = \"./data/train/\"\n",
    "\n",
    "X_train, y_train = makeData(path, labels)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 1/1: loss: 1.2344886417258072"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[236], line 22\u001b[0m\n\u001b[0;32m      1\u001b[0m nn \u001b[39m=\u001b[39m NeauralNetwork(layers\u001b[39m=\u001b[39m[\n\u001b[0;32m      2\u001b[0m         Conv2d(\u001b[39m10\u001b[39m, (\u001b[39m5\u001b[39m, \u001b[39m5\u001b[39m), stride\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m      3\u001b[0m         Conv2d(\u001b[39m20\u001b[39m, (\u001b[39m7\u001b[39m, \u001b[39m7\u001b[39m), stride\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m     epochs\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     20\u001b[0m )\n\u001b[1;32m---> 22\u001b[0m nn\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "Cell \u001b[1;32mIn[232], line 162\u001b[0m, in \u001b[0;36mNeauralNetwork.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepochs):\n\u001b[0;32m    161\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(y)):\n\u001b[1;32m--> 162\u001b[0m         pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(X[i])\n\u001b[0;32m    164\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n\u001b[0;32m    165\u001b[0m             \u001b[39m# process_percent = int(iter / epoch_len * 10)\u001b[39;00m\n\u001b[0;32m    166\u001b[0m             \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m Epoch \u001b[39m\u001b[39m{\u001b[39;00m_\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepochs\u001b[39m}\u001b[39;00m\u001b[39m: loss: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlossFunction(y[i],\u001b[39m \u001b[39mpred)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,end\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[232], line 200\u001b[0m, in \u001b[0;36mNeauralNetwork.forward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    197\u001b[0m X_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcopy(X)\n\u001b[0;32m    199\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m--> 200\u001b[0m     X_ \u001b[39m=\u001b[39m layer(X_)\n\u001b[0;32m    202\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msoftmax:\n\u001b[0;32m    203\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprobs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexp(X_)\n",
      "Cell \u001b[1;32mIn[231], line 219\u001b[0m, in \u001b[0;36mConv2d.__call__\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output[i, j] \u001b[39m=\u001b[39m (tensor[axis1_x1:axis1_x2, axis2_y1:axis2_y2] \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel)\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m))\n\u001b[0;32m    218\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_kernel_gradient \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tensor[axis1_x1:axis1_x2, axis2_y1:axis2_y2] \u001b[39m*\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output[i, j] \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m) \u001b[39m# ReLU implementation\u001b[39;00m\n\u001b[1;32m--> 219\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_gradient[axis1_x1:axis1_x2, axis2_y1:axis2_y2] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel\u001b[39m.\u001b[39;49msum(axis\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, keepdims\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    222\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivationFunction(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output) \u001b[39m# + self.bias\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[39m# May be added Max pooling\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[39m# if self.pooling == \"max\":\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[39m#     return output.max(axis=(0, 1))[np.newaxis, ...] # (1, output_shape)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Samvel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:46\u001b[0m, in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_amin\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     43\u001b[0m           initial\u001b[39m=\u001b[39m_NoValue, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m     44\u001b[0m     \u001b[39mreturn\u001b[39;00m umr_minimum(a, axis, \u001b[39mNone\u001b[39;00m, out, keepdims, initial, where)\n\u001b[1;32m---> 46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sum\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     47\u001b[0m          initial\u001b[39m=\u001b[39m_NoValue, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m     48\u001b[0m     \u001b[39mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n\u001b[0;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_prod\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     51\u001b[0m           initial\u001b[39m=\u001b[39m_NoValue, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nn = NeauralNetwork(layers=[\n",
    "        Conv2d(10, (5, 5), stride=3, activation='relu'),\n",
    "        Conv2d(20, (7, 7), stride=5, activation='relu'),\n",
    "        Conv2d(30, (3, 3), stride=2, activation='relu'),\n",
    "        Conv2d(80, (3, 3), stride=1, activation='relu', pooling=\"average\"),\n",
    "\n",
    "        DenseLayer(size=3),\n",
    "        # DenseLayer(size=40, activation=\"sigmoid\"),\n",
    "        # DenseLayer(size=40, activation=\"relu\"),\n",
    "        # DenseLayer(size=40, activation=\"relu\"),\n",
    "        # DenseLayer(size=1),\n",
    "    ],\n",
    "    loss_function = \"cross_entropy\",\n",
    "    learning_rate=0.01,\n",
    "    softmax=True,\n",
    "    verbose=True,\n",
    "    optimizer=\"gd\",\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "nn.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
